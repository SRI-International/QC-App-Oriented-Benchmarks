{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QED-C Application-Oriented Benchmarks - Qiskit - Image Recognition\n",
    "\n",
    "The notebook contains specific examples for the Image Recognition benchmark program.\n",
    "Configure and run the cell below with the desired execution settings.\n",
    "Then configure and run the remaining cell(s), each one a variation of this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_qubits=4\n",
    "max_qubits=6\n",
    "max_circuits=1\n",
    "num_shots=1000\n",
    "\n",
    "#backend_id=\"qasm_simulator\"\n",
    "backend_id=\"statevector_simulator\"\n",
    "hub=\"\"; group=\"\"; project=\"\"\n",
    "provider_backend = None\n",
    "exec_options = {}\n",
    "\n",
    "# # ==========================\n",
    "# # *** If using IBM Quantum hardware, run this once to authenticate\n",
    "# from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "# QiskitRuntimeService.save_account('YOUR_API_TOKEN_HERE')  # only need to do this first time\n",
    "\n",
    "# # *** If you use `ibm_quantum` channel, set hub, group, and project name here\n",
    "# hub=\"YOUR_HUB_NAME\"; group=\"YOUR_GROUP_NAME\"; project=\"YOUR_PROJECT_NAME\"\n",
    "\n",
    "# # *** If you use `ibm_cloud` channel, set hub, group, and project name here\n",
    "# hub=\"\"; group=\"\"; project=\"Cloud Resource Name (CRN) or service name\"\n",
    "\n",
    "# *** This example shows how to specify an IBMQ backend using a known \"backend_id\"\n",
    "#     See the App-Oriented Benchmarks setup page documentation for more info ob backends and options. \n",
    "# exec_options = {\n",
    "#     \"use_ibm_quantum_platform\": False,\n",
    "#     \"use_sessions\": False,\n",
    "# }\n",
    "# backend_id=\"ibm_kyiv\"\n",
    "\n",
    "# # ==========================\n",
    "# # *** If using Azure Quantum, use this hub identifier and specify the desired backend_id\n",
    "# # Identify your resources with env variables AZURE_QUANTUM_RESOURCE_ID and AZURE_QUANTUM_LOCATION\n",
    "# hub=\"azure-quantum\"; group=\"open\"; project=\"QED-C App-Oriented Benchmarks - Qiskit Version\"\n",
    "# backend_id=\"<YOUR_BACKEND_NAME_HERE>\"\n",
    "\n",
    "# # ==========================\n",
    "# The remaining examples create a provider instance and get a backend from it\n",
    "\n",
    "# # An example using IonQ provider\n",
    "# from qiskit_ionq import IonQProvider\n",
    "# provider = IonQProvider()   # Be sure to set the QISKIT_IONQ_API_TOKEN environment variable\n",
    "# provider_backend = provider.get_backend(\"ionq_qpu\")\n",
    "# backend_id=\"ionq_qpu\"\n",
    "\n",
    "# # An example using BlueQubit provider\n",
    "# import os, bluequbit, _common.executors.bluequbit_executor as bluequbit_executor\n",
    "# provider_backend = bluequbit.init()\n",
    "# backend_id=\"BlueQubit-CPU\"\n",
    "# exec_options = { \"executor\": bluequbit_executor.run, \"device\":'cpu' }\n",
    "\n",
    "# # *** Here's an example of using a typical custom provider backend (e.g. AQT simulator)\n",
    "# import os\n",
    "# from qiskit_aqt_provider import AQTProvider\n",
    "# provider = AQTProvider(os.environ.get('AQT_ACCESS_KEY'))    # get your key from environment\n",
    "# provider_backend = provider.backends.aqt_qasm_simulator_noise_1\n",
    "# backend_id=\"aqt_qasm_simulator_noise_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom optimization options can be specified in this cell (below is an example)\n",
    "\n",
    "# # Example of pytket Transformer\n",
    "# import _common.transformers.tket_optimiser as tket_optimiser\n",
    "# exec_options.update({ \"optimization_level\": 0, \"layout_method\":'sabre', \"routing_method\":'sabre', \"transformer\": tket_optimiser.high_optimisation })\n",
    "\n",
    "# # Define a custom noise model to be used during execution\n",
    "# import _common.custom.custom_qiskit_noise_model as custom_qiskit_noise_model\n",
    "# exec_options.update({ \"noise_model\": custom_qiskit_noise_model.my_noise_model() })\n",
    "\n",
    "# # Example of mthree error mitigation\n",
    "# import _common.postprocessors.mthree.mthree_em as mthree_em\n",
    "# exec_options.update({ \"postprocessor\": mthree_em.get_mthree_handlers(backend_id, provider_backend) })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition - Method 1 - Fidelity of Ansatz\n",
    "\n",
    "This benchmark is similar to benchmarks at the top-level in that it executes a quantum circuit to measure its fidelity of execution on a specific backend system.\n",
    "Here, the circuit tested is ansatz used in the image recognition benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from image_recognition.qiskit import image_recognition_benchmark\n",
    "\n",
    "# Arguments applicable to Image Recognition benchmark method (1)\n",
    "hl_app_args = dict(\n",
    "    \n",
    "    thetas_array=None,          # specify a custom thetas_array\n",
    "    parameterized=False,        # use Parameter objects in circuit, cache transpiled circuits for performance\n",
    ")\n",
    "\n",
    "# Run the benchmark in method 1\n",
    "image_recognition_benchmark.run(\n",
    "    min_qubits=min_qubits, max_qubits=max_qubits, max_circuits=max_circuits, num_shots=num_shots,\n",
    "    method=1,\n",
    "    backend_id=backend_id, provider_backend=provider_backend,\n",
    "    hub=hub, group=group, project=project, exec_options=exec_options,\n",
    "    **hl_app_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition - Method 2 - Training the Algorithm\n",
    "\n",
    "This method executes the benchmark as a Variational Quantum Eigensolver (VQE) that uses the ansatz tested in method (1).\n",
    "This method trains the algorithm to find the set of angles that best fits the image recognition function. These angles are stored in a data file for use in method 3, the test method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_recognition.qiskit import image_recognition_benchmark\n",
    "\n",
    "# Arguments specific to Image Recognition benchmark method (2)\n",
    "hl_app_args = dict(\n",
    "  \n",
    "    thetas_array=None,          # specify a custom thetas_array\n",
    "    parameterized=False,        # use Parameter objects in circuit, cache transpiled circuits for performance\n",
    "       \n",
    "    train_size=200,\n",
    "    test_size=50,\n",
    "    batch_size=50,              # size of image batch\n",
    "    test_pass_count=30,         # number of test passes\n",
    "    \n",
    "    max_iter=50,                # maximum minimizer iterations to perform  \n",
    "    comfort=True,               # show 'comfort dots' during execution\n",
    ")\n",
    "\n",
    "image_recognition_benchmark.verbose=False\n",
    "\n",
    "# Run the benchmark in method 2\n",
    "image_recognition_benchmark.run(\n",
    "    min_qubits=min_qubits, max_qubits=max_qubits, max_circuits=max_circuits, num_shots=num_shots,\n",
    "    method=2, \n",
    "    backend_id=backend_id, provider_backend=provider_backend,\n",
    "    hub=hub, group=group, project=project, exec_options=exec_options,\n",
    "    **hl_app_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition - Method 3 - Testing Against Unknown Images\n",
    "\n",
    "This method executes the algorithm against a set of unknown test images, using the parameters identified during the training pass in method 2.\n",
    "The figure of merit is the accuracy by which the algorithm is able to recognize the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_recognition.qiskit import image_recognition_benchmark\n",
    "\n",
    "# Arguments specific to Image Recognition benchmark method (2)\n",
    "hl_app_args = dict(\n",
    "  \n",
    "    thetas_array=None,          # specify a custom thetas_array\n",
    "    parameterized=False,        # use Parameter objects in circuit, cache transpiled circuits for performance\n",
    "    \n",
    "    train_size=200,\n",
    "    test_size=50,\n",
    "    batch_size=50,              # size of image batch\n",
    "    test_pass_count=30,         # number of test passes\n",
    "    \n",
    "    comfort=True,               # show 'comfort dots' during execution\n",
    ")\n",
    "\n",
    "image_recognition_benchmark.verbose=False\n",
    "\n",
    "# Run the benchmark in method 3\n",
    "image_recognition_benchmark.run(\n",
    "    min_qubits=min_qubits, max_qubits=max_qubits, max_circuits=max_circuits, num_shots=num_shots,\n",
    "    method=3, \n",
    "    backend_id=backend_id, provider_backend=provider_backend,\n",
    "    hub=hub, group=group, project=project, exec_options=exec_options,\n",
    "    **hl_app_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
