{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QED-C Application-Oriented Benchmarks - Qiskit - Image Recognition\n",
    "\n",
    "The notebook contains specific examples for the Image Recognition benchmark program.\n",
    "Configure and run the cell below with the desired execution settings.\n",
    "Then configure and run the remaining cell(s), each one a variation of this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_qubits=4\n",
    "max_qubits=6\n",
    "max_circuits=1\n",
    "num_shots=1000\n",
    "\n",
    "#backend_id=\"qasm_simulator\"\n",
    "backend_id=\"statevector_simulator\"\n",
    "hub=\"ibm-q\"; group=\"open\"; project=\"main\"\n",
    "provider_backend = None\n",
    "exec_options = {}\n",
    "\n",
    "# # ==========================\n",
    "# # *** If using IBMQ hardware, run this once to authenticate\n",
    "# from qiskit import IBMQ\n",
    "# IBMQ.save_account('YOUR_API_TOKEN_HERE')\n",
    "\n",
    "# # *** If you are part of an IBMQ group, set hub, group, and project name here\n",
    "# hub=\"YOUR_HUB_NAME\"; group=\"YOUR_GROUP_NAME\"; project=\"YOUR_PROJECT_NAME\"\n",
    "\n",
    "# # *** This example shows how to specify an IBMQ backend using a known \"backend_id\"\n",
    "# exec_options = { \"optimization_level\":3, \"use_sessions\":True, \"resilience_level\":1}\n",
    "# backend_id=\"ibmq_belem\"\n",
    "\n",
    "# # ==========================\n",
    "# # *** If using Azure Quantum, use this hub identifier and specify the desired backend_id\n",
    "# # Identify your resources with env variables AZURE_QUANTUM_RESOURCE_ID and AZURE_QUANTUM_LOCATION\n",
    "# hub=\"azure-quantum\"; group=\"open\"; project=\"QED-C App-Oriented Benchmarks - Qiskit Version\"\n",
    "# backend_id=\"<YOUR_BACKEND_NAME_HERE>\"\n",
    "\n",
    "# # ==========================\n",
    "# The remaining examples create a provider instance and get a backend from it\n",
    "\n",
    "# # An example using IonQ provider\n",
    "# from qiskit_ionq import IonQProvider\n",
    "# provider = IonQProvider()   # Be sure to set the QISKIT_IONQ_API_TOKEN environment variable\n",
    "# provider_backend = provider.get_backend(\"ionq_qpu\")\n",
    "# backend_id=\"ionq_qpu\"\n",
    "\n",
    "# # An example using BlueQubit provider\n",
    "# import sys\n",
    "# sys.path.insert(1, \"../..\")\n",
    "# import os, bluequbit, _common.executors.bluequbit_executor as bluequbit_executor\n",
    "# provider_backend = bluequbit.init()\n",
    "# backend_id=\"BlueQubit-CPU\"\n",
    "# exec_options = { \"executor\": bluequbit_executor.run, \"device\":'cpu' }\n",
    "\n",
    "# # *** Here's an example of using a typical custom provider backend (e.g. AQT simulator)\n",
    "# import os\n",
    "# from qiskit_aqt_provider import AQTProvider\n",
    "# provider = AQTProvider(os.environ.get('AQT_ACCESS_KEY'))    # get your key from environment\n",
    "# provider_backend = provider.backends.aqt_qasm_simulator_noise_1\n",
    "# backend_id=\"aqt_qasm_simulator_noise_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom optimization options can be specified in this cell (below is an example)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../../\")\n",
    "\n",
    "# # Example of pytket Transformer\n",
    "# import _common.transformers.tket_optimiser as tket_optimiser\n",
    "# exec_options.update({ \"optimization_level\": 0, \"layout_method\":'sabre', \"routing_method\":'sabre', \"transformer\": tket_optimiser.high_optimisation })\n",
    "\n",
    "# # Define a custom noise model to be used during execution\n",
    "# import _common.custom.custom_qiskit_noise_model as custom_qiskit_noise_model\n",
    "# exec_options.update({ \"noise_model\": custom_qiskit_noise_model.my_noise_model() })\n",
    "\n",
    "# # Example of mthree error mitigation\n",
    "# import _common.postprocessors.mthree.mthree_em as mthree_em\n",
    "# exec_options.update({ \"postprocessor\": mthree_em.get_mthree_handlers(backend_id, provider_backend) })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition - Method 1 - Fidelity of Ansatz\n",
    "\n",
    "This benchmark is similar to benchmarks at the top-level in that it executes a quantum circuit to measure its fidelity of execution on a specific backend system.\n",
    "Here, the circuit tested is ansatz used in the image recognition benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"image-recognition/qiskit\")\n",
    "import image_recognition_benchmark\n",
    "\n",
    "# Arguments applicable to Image Recognition benchmark method (1)\n",
    "hl_app_args = dict(\n",
    "    \n",
    "    thetas_array=None,          # specify a custom thetas_array\n",
    "    parameterized=False,        # use Parameter objects in circuit, cache transpiled circuits for performance\n",
    ")\n",
    "\n",
    "# Run the benchmark in method 1\n",
    "image_recognition_benchmark.run(\n",
    "    min_qubits=min_qubits, max_qubits=max_qubits, max_circuits=max_circuits, num_shots=num_shots,\n",
    "    method=1,\n",
    "    backend_id=backend_id, provider_backend=provider_backend,\n",
    "    hub=hub, group=group, project=project, exec_options=exec_options,\n",
    "    **hl_app_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition - Method 2 - Training the Algorithm\n",
    "\n",
    "This method executes the benchmark as a Variational Quantum Eigensolver (VQE) that uses the ansatz tested in method (1).\n",
    "This method trains the algorithm to find the set of angles that best fits the image recognition function. These angles are stored in a data file for use in method 3, the test method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"image-recognition/qiskit\")\n",
    "import image_recognition_benchmark\n",
    "\n",
    "# Arguments specific to Image Recognition benchmark method (2)\n",
    "hl_app_args = dict(\n",
    "  \n",
    "    thetas_array=None,          # specify a custom thetas_array\n",
    "    parameterized=False,        # use Parameter objects in circuit, cache transpiled circuits for performance\n",
    "       \n",
    "    train_size=200,\n",
    "    test_size=50,\n",
    "    batch_size=50,              # size of image batch\n",
    "    test_pass_count=30,         # number of test passes\n",
    "    \n",
    "    max_iter=50,                # maximum minimizer iterations to perform  \n",
    "    comfort=True,               # show 'comfort dots' during execution\n",
    ")\n",
    "\n",
    "image_recognition_benchmark.verbose=False\n",
    "\n",
    "# Run the benchmark in method 2\n",
    "image_recognition_benchmark.run(\n",
    "    min_qubits=min_qubits, max_qubits=max_qubits, max_circuits=max_circuits, num_shots=num_shots,\n",
    "    method=2, \n",
    "    backend_id=backend_id, provider_backend=provider_backend,\n",
    "    hub=hub, group=group, project=project, exec_options=exec_options,\n",
    "    **hl_app_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Recognition - Method 3 - Testing Against Unknown Images\n",
    "\n",
    "This method executes the algorithm against a set of unknown test images, using the parameters identified during the training pass in method 2.\n",
    "The figure of merit is the accuracy by which the algorithm is able to recognize the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"image-recognition/qiskit\")\n",
    "import image_recognition_benchmark\n",
    "\n",
    "# Arguments specific to Image Recognition benchmark method (2)\n",
    "hl_app_args = dict(\n",
    "  \n",
    "    thetas_array=None,          # specify a custom thetas_array\n",
    "    parameterized=False,        # use Parameter objects in circuit, cache transpiled circuits for performance\n",
    "    \n",
    "    train_size=200,\n",
    "    test_size=50,\n",
    "    batch_size=50,              # size of image batch\n",
    "    test_pass_count=30,         # number of test passes\n",
    "    \n",
    "    comfort=True,               # show 'comfort dots' during execution\n",
    ")\n",
    "\n",
    "image_recognition_benchmark.verbose=False\n",
    "\n",
    "# Run the benchmark in method 3\n",
    "image_recognition_benchmark.run(\n",
    "    min_qubits=min_qubits, max_qubits=max_qubits, max_circuits=max_circuits, num_shots=num_shots,\n",
    "    method=3, \n",
    "    backend_id=backend_id, provider_backend=provider_backend,\n",
    "    hub=hub, group=group, project=project, exec_options=exec_options,\n",
    "    **hl_app_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-test-ml",
   "language": "python",
   "name": "qiskit-test-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
