{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/zvckwm_14xngvtq24phdf3p80000gn/T/ipykernel_52166/1237808633.py:32: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n",
      "  sampler = Sampler()\n",
      "/var/folders/m9/zvckwm_14xngvtq24phdf3p80000gn/T/ipykernel_52166/1237808633.py:33: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  qnn = SamplerQNN(\n",
      "No interpret function given, output_shape will be automatically determined as 2^num_virtual_qubits.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TorchConnector.forward() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         q_values = \u001b[43mqnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     action = \u001b[38;5;28mint\u001b[39m(torch.argmax(q_values))\n\u001b[32m     90\u001b[39m next_state, reward, terminated, truncated, _ = env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/SRI_QRL/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/SRI_QRL/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mQuantumQNetwork.forward\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     57\u001b[39m w = \u001b[38;5;28mself\u001b[39m.weights.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# forward through QNN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m q_vals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# map q_vals to action values: repeat or simple linear layer\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# here simply pad/truncate to n_actions\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obs_size >= \u001b[38;5;28mself\u001b[39m.n_actions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/SRI_QRL/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/SRI_QRL/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: TorchConnector.forward() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "# simple_qrl.py\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# --- Quantum Q-network ---\n",
    "class QuantumQNetwork(nn.Module):\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super().__init__()\n",
    "        self.obs_size = obs_size\n",
    "        self.n_actions = n_actions\n",
    "        # prepare Qiskit parameters for encoding and variational\n",
    "        self.x_params = ParameterVector('x', obs_size)\n",
    "        self.w_params = ParameterVector('w', obs_size)\n",
    "\n",
    "        # build circuit: RX for data, RZ for weights, measure Z\n",
    "        qc = QuantumCircuit(obs_size)\n",
    "        for i in range(obs_size):\n",
    "            qc.rx(self.x_params[i], i)\n",
    "            qc.rz(self.w_params[i], i)\n",
    "        qc.measure_all()\n",
    "\n",
    "        # create SamplerQNN and TorchConnector\n",
    "        sampler = Sampler()\n",
    "        qnn = SamplerQNN(\n",
    "            circuit=qc,\n",
    "            input_params=self.x_params,\n",
    "            weight_params=self.w_params,\n",
    "            sampler=sampler,\n",
    "            output_shape=(obs_size,)\n",
    "        )\n",
    "        self.model = TorchConnector(qnn)\n",
    "\n",
    "    def forward(self, state):\n",
    "        # state: scalar int or tensor [1]\n",
    "        if isinstance(state, int):\n",
    "            s = state\n",
    "        else:\n",
    "            s = int(state.item())\n",
    "        # encode as one-hot angles\n",
    "        x = torch.zeros(self.obs_size)\n",
    "        x[s] = np.pi\n",
    "        x = x.unsqueeze(0)  # batch dim\n",
    "        # weights: combine nn.Parameter vector\n",
    "        if not hasattr(self, 'weights'):\n",
    "            # initialize learnable weights once on first forward\n",
    "            self.weights = nn.Parameter(torch.randn(self.obs_size) * 2 * np.pi)\n",
    "            self.register_parameter('weights', self.weights)\n",
    "        w = self.weights.unsqueeze(0)\n",
    "        # forward through QNN\n",
    "        q_vals = self.model(x, w)\n",
    "        # map q_vals to action values: repeat or simple linear layer\n",
    "        # here simply pad/truncate to n_actions\n",
    "        if self.obs_size >= self.n_actions:\n",
    "            return q_vals[:, :self.n_actions]\n",
    "        else:\n",
    "            # replicate last value\n",
    "            pad = q_vals[:, -1].repeat(1, self.n_actions - self.obs_size)\n",
    "            return torch.cat([q_vals, pad], dim=1)\n",
    "\n",
    "# --- Training loop ---\n",
    "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "obs_size = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "qnet = QuantumQNetwork(obs_size, n_actions)\n",
    "opt = optim.Adam(qnet.parameters(), lr=0.01)\n",
    "gamma = 0.99\n",
    "\n",
    "episodes = 100\n",
    "for episode in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # epsilon-greedy\n",
    "        if np.random.rand() < 0.1:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = qnet(state)\n",
    "            action = int(torch.argmax(q_values))\n",
    "\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        q_current = qnet(state)[0, action]\n",
    "        with torch.no_grad():\n",
    "            q_next_vals = qnet(next_state)\n",
    "            q_next = torch.max(q_next_vals)\n",
    "            target = reward + (1 - done) * gamma * q_next\n",
    "        loss = (q_current - target).pow(2)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "        print(f\"Episode {episode} completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qrl_circuit(x_params, s_params, w_params, obs_size):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SRI_QRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
